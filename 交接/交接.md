我主要负责gims的7个模块：
- monitor-admin
- monitor-colletcor
- monitor-metadata-synch
- monitor-proxy
- monitor-query
- monitor-transform
- monitor-web
---
## monitor-admin
### 复杂度：低
对c_collector_group,c_collector_logstash,gops_client的增删改查的管理界面。

---
## monitor-colletcor
### 复杂度：低
数据源的第三种采集方式，自主上报。

通过netty去开启接口去接收用户发来的数据并发送kafka，主要是对netty的运用。

---
## monitor-metadata-synch
### 复杂度：中
共分为分为两块
1. 将gops的数据库数据同步到gims的数据库中。
2. 将四种集采方式的配置转入到gims的数据库中。
### 注意点：
1. 运用了一些设计模式，根据我定义的规则加入新的采集方式，可实现自动的注册与发现。
2. 由于有外键约束，同步表逻辑是有顺序的。

---
## monitor-proxy
### 复杂度：中
数据源的第二种采集方式，主动采集。

通过gims的服务器去采集目标机，每个proxy就是一种采集方式，例如：http、snmp、ntp等，可实现动态的添加proxy。

---
## monitor-query
### 复杂度：高

对用户输入的sql语句利用druid工具进行分析，对语法树增删改查来添加表前缀、event_time时间范围、做count操作等等，还有检查用户访问的表是否有该表的权限。druid的SQL Parser文档地址：https://github.com/alibaba/druid/wiki/SQL-Parser

---
## monitor-transform
### 复杂度：高

对三种采集方式所上报到kafka的数据进行处理，将@timestamp或用户自定义时间字段转为event_time，并上报到大数据平台。

对日志采集方式有额外处理，根据用户写的grok语法，对每条日志拆分字段。

---
## monitor-web
### 复杂度：中
主要是对metadata的数据进行转换供前端使用。

---